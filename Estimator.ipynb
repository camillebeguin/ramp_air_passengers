{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic librairies\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import calendar\n",
    "import holidays\n",
    "\n",
    "# import utils\n",
    "import holidays\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# import preprocessing functions\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OrdinalEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import pipeline functions\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# import models\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LassoLarsCV, ElasticNetCV\n",
    "\n",
    "# other functions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 11128\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'initial_data.csv'), parse_dates=['DateOfDeparture'])\n",
    "print('Number of observations: %.f' % (df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647\n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734\n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883\n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202\n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('log_PAX', axis=1), \n",
    "                                                    df['log_PAX'], train_size=0.8, \n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data(X):\n",
    "    filepath = os.path.join('data', 'external_data.csv')\n",
    "    \n",
    "    external_data = pd.read_csv(filepath)\n",
    "    \n",
    "    X = X.copy()  # modify a copy of X\n",
    "\n",
    "    # create a \"year\" and \"month\" columns to enable the merge\n",
    "    X.loc[:, 'DateOfDeparture'] = pd.to_datetime(X.loc[:, 'DateOfDeparture'])\n",
    "    external_data.loc[:, 'DateOfDeparture'] = pd.to_datetime(external_data.loc[:, 'DateOfDeparture'])\n",
    "    \n",
    "    X['connection'] = X['Departure'] + '_' + X['Arrival']\n",
    "    X['connection'] = ['_'.join(np.sort(x.split('_'))) for x in X['connection']]\n",
    "\n",
    "    external_data['event_level_dep_arr'] = external_data['event_level_dep'] * external_data['event_level_arr']\n",
    "    external_data.drop(columns=['event_level_dep', 'event_level_arr'], inplace=True)\n",
    "\n",
    "    X_merged = X.merge(external_data, how='left', on=['Departure', 'Arrival', 'DateOfDeparture'])\n",
    "    \n",
    "    X_merged.drop(columns=['mean_temp_dep', 'departures_performed'], inplace=True)\n",
    "\n",
    "    return X_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "    # Make sure that DateOfDeparture is of datetime format\n",
    "    X_encoded.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_encoded.loc[:, 'DateOfDeparture'])\n",
    "\n",
    "    # Encode the DateOfDeparture\n",
    "    #X_encoded.loc[:, 'day'] = X_encoded['DateOfDeparture'].dt.day\n",
    "    X_encoded.loc[:, 'weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "    #X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "    X_encoded.loc[:, 'is_weekend'] = [True if x in [5, 6] else False for x in X_encoded.loc[:, 'weekday']]\n",
    "    X_encoded.loc[:, 'n_days'] = X_encoded['DateOfDeparture'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)\n",
    "\n",
    "    # Cyclical encoding of Dates\n",
    "    X_encoded.loc[:, 'day_of_year'] = X_encoded['DateOfDeparture'].apply(\n",
    "        lambda x: (x.date() - datetime.date(x.year, 1, 1)).days)\n",
    "    \n",
    "    days_in_year = np.where(X_encoded[\"year\"].apply(lambda y: calendar.isleap(y)), 366, 365)\n",
    "    X_encoded['sin_doy'] = np.sin(2*np.pi*X_encoded[\"day_of_year\"]/days_in_year)\n",
    "    X_encoded['cos_doy'] = np.cos(2*np.pi*X_encoded[\"day_of_year\"]/days_in_year)\n",
    "    X_encoded['sin_dow'] = np.sin(2*np.pi*X_encoded[\"weekday\"]/7)\n",
    "    X_encoded['cos_dow'] = np.cos(2*np.pi*X_encoded[\"weekday\"]/7)\n",
    "    \n",
    "    # Encode holidays\n",
    "    us_holidays = holidays.US()\n",
    "    X_encoded.loc[:, 'is_holiday'] = [x in us_holidays for x in X_encoded['DateOfDeparture']]\n",
    "    X_encoded.loc[:, 'is_beginning_holidays'] = [\n",
    "        (x not in us_holidays) & (x + datetime.timedelta(days=1) in us_holidays) for x in X_encoded['DateOfDeparture']]\n",
    "    X_encoded.loc[:, 'is_end_holidays'] = [(x in us_holidays) & (x + datetime.timedelta(days=1) not in us_holidays) for\n",
    "                                           x in X_encoded['DateOfDeparture']]\n",
    "\n",
    "    # add distance to closest holidays\n",
    "    X_encoded = X_encoded.sort_values('DateOfDeparture')\n",
    "    X_encoded['dumb1'] = X_encoded['dumb2'] = X_encoded[\"DateOfDeparture\"][X_encoded[\"is_holiday\"]]\n",
    "    X_encoded[\"dumb1\"] = X_encoded[\"dumb1\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    X_encoded[\"dumb2\"] = X_encoded[\"dumb2\"].fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    X_encoded[\"distance_to_previous\"] = pd.to_numeric(np.abs(X_encoded[\"dumb1\"] - X_encoded[\"DateOfDeparture\"]).dt.days)\n",
    "    X_encoded[\"distance_to_next\"] = pd.to_numeric(np.abs(X_encoded[\"dumb2\"] - X_encoded[\"DateOfDeparture\"]).dt.days)\n",
    "    X_encoded[\"holidays_distance\"] = np.minimum(X_encoded.distance_to_previous, X_encoded.distance_to_next)\n",
    "    X_encoded.drop(columns=['dumb1', 'dumb2', 'distance_to_previous', 'distance_to_next'], inplace=True)\n",
    "\n",
    "    X_encoded.drop(columns=['DateOfDeparture', 'day_of_year'], inplace=True)\n",
    "    \n",
    "    return X_encoded.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(model_type='lgb'):\n",
    "\n",
    "    # preprocessing the data\n",
    "    data_merger = FunctionTransformer(_merge_external_data)\n",
    "    date_encoder = FunctionTransformer(_encode_dates)\n",
    "\n",
    "    # create a preprocessor\n",
    "    preprocessor = make_pipeline(data_merger, date_encoder)\n",
    "    \n",
    "    # encode categorical columns\n",
    "    target_cols = ['connection', 'event_level_dep_arr', 'year', 'month']\n",
    "    categorical_cols = ['Departure', 'Arrival']\n",
    "    \n",
    "    encoder = make_column_transformer(\n",
    "        (OrdinalEncoder(), categorical_cols),\n",
    "        (TargetEncoder(), target_cols),\n",
    "        remainder='passthrough'  # passthrough numerical columns as they are\n",
    "    )\n",
    "    \n",
    "    # initialize models\n",
    "    lgb_model = LGBMRegressor(objective='regression', random_state=42, metric=\"rmse\", learning_rate=0.114, max_depth=41,\n",
    "                     n_estimators=775, num_leaves=20, reg_lambda=0.123, reg_alpha=0.46)\n",
    "    xgb_model = XGBRegressor(objective=\"reg:squarederror\", random_state=42, reg_alpha=0.795, reg_lambda=0.172,\n",
    "                            colsample_bytree=0.836, gamma=0.042, learning_rate=0.114,\n",
    "                            max_depth=13, subsample=0.920)\n",
    "    cat_model = CatBoostRegressor(loss_function='RMSE', verbose=False)\n",
    "\n",
    "    if model_type == 'lgb':\n",
    "        return make_pipeline(preprocessor, encoder, lgb_model)\n",
    "    elif model_type == 'xgb':\n",
    "        return make_pipeline(preprocessor, encoder, xgb_model)\n",
    "    elif model_type == 'cat':\n",
    "        return make_pipeline(preprocessor, encoder, cat_model)\n",
    "    else: \n",
    "        return \"Model not available\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_type, X_train, y_train):\n",
    "    if model_type == None:\n",
    "        model_type = 'lgb'\n",
    "        \n",
    "    pipeline = get_estimator(model_type)\n",
    "    \n",
    "    # get training time\n",
    "    start = timer()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    end = timer()\n",
    "    print('Fitting time on the full training set is %.3f seconds' % (end - start))\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='neg_mean_squared_error')\n",
    "    print('The cross-validation RMSE is %.5f' % np.mean(np.sqrt(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time on the full training set is 6.168 seconds\n",
      "The cross-validation RMSE is 0.32974\n"
     ]
    }
   ],
   "source": [
    "# Catboost Regressor\n",
    "evaluate_model('cat', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time on the full training set is 2.914 seconds\n",
      "The cross-validation RMSE is 0.33545\n"
     ]
    }
   ],
   "source": [
    "# LGBM Regressor\n",
    "evaluate_model('lgb', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time on the full training set is 4.095 seconds\n",
      "The cross-validation RMSE is 0.34550\n"
     ]
    }
   ],
   "source": [
    "# XGB Regressor\n",
    "evaluate_model('xgb', X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
